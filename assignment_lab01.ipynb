{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Classification of Stayed/Churned Customers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset description\n",
    "\n",
    "The Customer Churn table contains information on all 3,757 customers from a Telecommunications company in California in Q2 2022. \n",
    "The dataset contains three features:\n",
    "- **Tenure in Months**: Number of months the customer has stayed with the company\n",
    "- **Monthly Charge**: The amount charged to the customer monthly\n",
    "- **Age**: Customer's age\n",
    "\n",
    "The aim of the task is to predict if a customer will churn or not based on the three features.\n",
    "\n",
    "<center>\n",
    "\n",
    "![COVER](data/dataset-cover.png \"COVER\")\n",
    "\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first **import** all **the packages** that are needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn import linear_model, preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change some global settings for layout purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you are in the jupyter notebook environment you can change the 'inline' option with 'notebook' to get interactive plots\n",
    "%matplotlib notebook\n",
    "# change the limit on the line length and crop to 0 very small numbers, for clearer printing\n",
    "np.set_printoptions(linewidth=500, suppress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A) Perceptron\n",
    "In the following cells we will **implement** the **perceptron** algorithm and use it to learn a halfspace."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TO DO (A.0):** **Set** the random **seed** using your **ID**. If you need to change it for testing add a constant explicitly, eg.: 1234567 + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "IDnumber = 1234 # YOUR_ID\n",
    "np.random.seed(IDnumber)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Dataset\n",
    "The dataset is a `.csv` file containing three input features and a label. Here is an example of the first 4 rows of the dataset: \n",
    "\n",
    "<center>\n",
    "\n",
    "Tenure in Months | Monthly Charge | Age | Customer Status |\n",
    "| -----------------| ---------------|-----|-----------------|\n",
    "| 9 | 65.6 | 37 | 0 |\n",
    "| 9 | -4.0 | 46 | 0 |\n",
    "| 4 | 73.9 | 50 | 1 |\n",
    "| ... | ... | ... | ... |\n",
    "\n",
    "</center>\n",
    "\n",
    "Customer Status is 0 if the customer has stayed with the company and 1 if the customer has churned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(filename):\n",
    "    data_train = pd.read_csv(filename)\n",
    "    #permute the data\n",
    "    data_train = data_train.sample(frac=1).reset_index(drop=True) # shuffle the data\n",
    "    X = data_train.iloc[:, 0:3].values # Get first two columns as the input\n",
    "    Y = data_train.iloc[:, 3].values # Get the third column as the label\n",
    "    Y = 2*Y-1 # Make sure labels are -1 or 1 (0 --> -1, 1 --> 1)\n",
    "    return X,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "X, Y = load_dataset('data/telecom_customer_churn_cleaned.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to differentiate (classify) between **class \"1\" (churned)** and **class \"-1\" (stayed)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples in the train set: 2817\n",
      "Number of samples in the test set: 940\n",
      "\n",
      "Number of night instances in test: 470\n",
      "Number of day instances in test: 470\n",
      "Mean of the training input data: [0. 0. 0.]\n",
      "Std of the training input data: [1. 1. 1.]\n",
      "Mean of the test input data: [-0.03859173 -0.01057507  0.05557416]\n",
      "Std of the test input data: [0.96338446 0.99562818 1.0407794 ]\n"
     ]
    }
   ],
   "source": [
    "# compute the splits\n",
    "m_training = int(X.shape[0] * 0.75) \n",
    "\n",
    "# m_test is the number of samples in the test set (total-training)\n",
    "m_test = X.shape[0] - m_training \n",
    "\n",
    "# X_training = instances for training set\n",
    "X_training = X[:m_training,:] \n",
    "# Y_training = labels for the training set\n",
    "Y_training = Y[:m_training, ] \n",
    "\n",
    "# X_test = instances for test set\n",
    "X_test = X[m_training:, :]  \n",
    "# Y_test = labels for the test set\n",
    "Y_test = Y[m_training:,] \n",
    "\n",
    "print(\"Number of samples in the train set:\", X_training.shape[0])\n",
    "print(\"Number of samples in the test set:\", X_test.shape[0])\n",
    "print(\"\\nNumber of night instances in test:\", np.sum(Y_test==-1))\n",
    "print(\"Number of day instances in test:\", np.sum(Y_test==1))\n",
    "\n",
    "# standardize the input matrix\n",
    "# the transformation is computed on training data and then used on all the 3 sets\n",
    "scaler = preprocessing.StandardScaler().fit(X_training) \n",
    "\n",
    "np.set_printoptions(suppress=True) # sets to zero floating point numbers < min_float_eps\n",
    "X_training = scaler.transform(X_training) \n",
    "print (\"Mean of the training input data:\", X_training.mean(axis=0))\n",
    "print (\"Std of the training input data:\",X_training.std(axis=0))\n",
    "\n",
    "X_test = scaler.transform(X_test) \n",
    "print (\"Mean of the test input data:\", X_test.mean(axis=0))\n",
    "print (\"Std of the test input data:\", X_test.std(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_homogeneous(X_training, X_test):\n",
    "    # Add a 1 to each sample (homogeneous coordinates)\n",
    "    X_training = np.hstack( [np.ones( (X_training.shape[0], 1) ), X_training] )\n",
    "    X_test = np.hstack( [np.ones( (X_test.shape[0], 1) ), X_test] )\n",
    "    \n",
    "    return X_training, X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set in homogeneous coordinates:\n",
      "[[ 1.         -0.85681595  1.18553248 -0.90686994]\n",
      " [ 1.          1.33620809  1.44214767 -0.31393676]\n",
      " [ 1.          1.74998621  0.79394438 -0.01747016]\n",
      " [ 1.         -1.06370501  0.03742948  0.21970311]\n",
      " [ 1.         -0.11201533  0.25571902  1.93920935]\n",
      " [ 1.          1.50171934 -2.48373139 -0.25464344]\n",
      " [ 1.          1.29483028  0.88559266 -0.07676348]\n",
      " [ 1.          1.74998621 -1.47393398 -1.26262985]\n",
      " [ 1.         -0.73268252  0.47234223 -0.19535012]\n",
      " [ 1.          0.6741631  -1.43560833  0.45687638]]\n"
     ]
    }
   ],
   "source": [
    "# convert to homogeneous coordinates using the function above\n",
    "X_training, X_test = to_homogeneous(X_training, X_test)\n",
    "print(\"Training set in homogeneous coordinates:\")\n",
    "print(X_training[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_errors(current_w, X, Y):\n",
    "    # This function:\n",
    "    # computes the number of misclassified samples\n",
    "    # returns the index of the first misclassified samples\n",
    "    # if there are no misclassified samples, returns -1 as index\n",
    "    products = list()\n",
    "    for i in range(len(X)):\n",
    "        a = np.dot(current_w.T,np.dot(X[i],Y[i]))\n",
    "        products.append(a)\n",
    "        \n",
    "    pred = np.sign(products)\n",
    "    wrong = np.array([True if i<=0 else False for i in pred])\n",
    "    num_misclassified = wrong.sum()\n",
    "    \n",
    "    if num_misclassified > 0:\n",
    "        index_misclassified = np.where(wrong)[0][0]\n",
    "\n",
    "    else:\n",
    "        index_misclassified = -1# signaling value for termination\n",
    "    \n",
    "    return num_misclassified, index_misclassified\n",
    "\n",
    "\n",
    "        \n",
    "def perceptron_update(current_w, x, y):\n",
    "    # Place in this function the update rule of the perceptron algorithm\n",
    "    # Remember that numpy arrays can be treated as generalized variables\n",
    "    # therefore given array a = [1,2,3,4], the operation b = 10*a will yield\n",
    "    # b = [10, 20, 30, 40]\n",
    "    for i in range(len(x)):\n",
    "        a = np.dot(current_w.T,np.dot(x[i],y[i]))\n",
    "\n",
    "\n",
    "        if a <= 0:\n",
    "            current_w = current_w+(x[i]*y[i])\n",
    "\n",
    "    \n",
    "    new_w = current_w\n",
    "\n",
    "    return new_w\n",
    "    \n",
    "\n",
    "def perceptron_no_randomization(X, Y, max_num_iterations):\n",
    "    \n",
    "    # Initialize some support variables\n",
    "    num_samples = X.shape[0]\n",
    "    # best_errors will keep track of the best (minimum) number of errors\n",
    "    # seen throughout training, used for the update of the best_w variable\n",
    "    best_error = num_samples+1\n",
    "    \n",
    "    # Initialize the weights of the algorith with w=0\n",
    "    curr_w =np.zeros(X.shape[1]) # ADD YOUR CODE HERE\n",
    "    # The best_w variable will be used to keep track of the best solution\n",
    "    best_w = curr_w.copy()\n",
    "\n",
    "    # compute the number of misclassified samples and the index of the first of them\n",
    "    num_misclassified, index_misclassified = count_errors(curr_w, X, Y)\n",
    "    # update the 'best' variables\n",
    "    if num_misclassified < best_error:\n",
    "        best_error = num_misclassified# ADD YOUR CODE HERE\n",
    "        best_w = curr_w# ADD YOUR CODE HERE\n",
    "    \n",
    "    # initialize the number of iterations\n",
    "    num_iter = 0\n",
    "    # Main loop continue until all samples correctly classified or max # iterations reached\n",
    "    # Remember that to signify that no errors were found we set index_misclassified = -1\n",
    "    while index_misclassified != -1 and num_iter < max_num_iterations:\n",
    "\n",
    "        curr_w = perceptron_update(curr_w,X,Y)\n",
    "\n",
    "    \n",
    "        per = np.random.permutation(len(X))\n",
    "        X = X[per]\n",
    "        Y = Y[per]\n",
    "        \n",
    "        # repeat the error count and best variables update\n",
    "        num_misclassified, index_misclassified = count_errors(curr_w, X, Y)\n",
    "        # update the 'best' variables\n",
    "        if num_misclassified < best_error:\n",
    "            best_error = num_misclassified \n",
    "            best_w = curr_w \n",
    "        #print(num_misclassified)\n",
    "        # update the iteration number\n",
    "        num_iter += 1\n",
    "        \n",
    "\n",
    "        # Choose the misclassified sample with the lowest index at each iteration\n",
    "\n",
    "    # as required, return the best error as a ratio with respect to the total number of samples\n",
    "    best_error =  (best_error / len(X)) * 100 # ADD YOUR CODE HERE\n",
    "    \n",
    "    return best_w, best_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Error of perceptron (30 iterations): 26.020589279375223\n"
     ]
    }
   ],
   "source": [
    "# Now run the perceptron for 30 iterations\n",
    "w_found, error = perceptron_no_randomization(X_training,Y_training, 30)\n",
    "print(\"Training Error of perceptron (30 iterations): \" + str(error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error of perceptron (30 iterations): 24.04255319148936\n"
     ]
    }
   ],
   "source": [
    "errors, _ = count_errors(w_found, X_test,Y_test)\n",
    "\n",
    "true_loss_estimate = (errors / len(X_test))*100     # Error rate on the test set\n",
    "# NOTE: you can avoid using num_errors if you prefer, as long as true_loss_estimate is correct\n",
    "print(\"Test Error of perceptron (30 iterations): \" + str(true_loss_estimate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perceptron(X, Y, max_num_iterations):\n",
    "    # Use the previous function as a template to \n",
    "    # implement the random version of the perceptron algorithm\n",
    "    # Initialize some support variables\n",
    "    num_samples = X.shape[0]\n",
    "    # best_errors will keep track of the best (minimum) number of errors\n",
    "    # seen throughout training, used for the update of the best_w variable\n",
    "    best_error = num_samples+1\n",
    "    \n",
    "    # Initialize the weights of the algorith with w=0\n",
    "    curr_w =np.zeros(X.shape[1])\n",
    "    # The best_w variable will be used to keep track of the best solution\n",
    "    best_w = curr_w.copy()\n",
    "\n",
    "    # compute the number of misclassified samples and the index of the first of them\n",
    "    num_misclassified, index_misclassified = count_errors(curr_w, X, Y)\n",
    "    # update the 'best' variables\n",
    "    if num_misclassified < best_error:\n",
    "        best_error = num_misclassified\n",
    "        best_w = curr_w\n",
    "    \n",
    "    \n",
    "    num_iter = 0\n",
    "   \n",
    "    while index_misclassified != -1 and num_iter < max_num_iterations:\n",
    "        \n",
    "        curr_w = perceptron_update(curr_w,X,Y)\n",
    "\n",
    "        num_misclassified, index_misclassified = count_errors(curr_w, X, Y)\n",
    "        # update the 'best' variables\n",
    "        if num_misclassified < best_error:\n",
    "            best_error = num_misclassified \n",
    "            best_w = curr_w \n",
    "        #print(num_misclassified)\n",
    "        # update the iteration number\n",
    "        num_iter += 1\n",
    "        \n",
    "\n",
    "        # Choose the misclassified sample with the lowest index at each iteration\n",
    "\n",
    "    # as required, return the best error as a ratio with respect to the total number of samples\n",
    "    best_error =  (best_error / len(X)) * 100 \n",
    "    \n",
    "    return best_w, best_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Error of perceptron (30 iterations): 29.996450124245648\n",
      "Test Error of perceptron (30 iterations): 0.31170212765957445\n"
     ]
    }
   ],
   "source": [
    "# Now run the perceptron for 30 iterations\n",
    "w_found, error = perceptron(X_training,Y_training, 30)\n",
    "print(\"Training Error of perceptron (30 iterations): \" + str(error))\n",
    "\n",
    "errors, _ = count_errors(w_found, X_test,Y_test)\n",
    "\n",
    "true_loss_estimate = (errors / len(X_test))    # Error rate on the test set\n",
    "# NOTE: you can avoid using num_errors if you prefer, as long as true_loss_estimate is correct\n",
    "print(\"Test Error of perceptron (30 iterations): \" + str(true_loss_estimate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the loss with respect to the number of iterations\n",
    "%matplotlib inline\n",
    "plt.figure(figsize=(8,4))\n",
    "\n",
    "num_iters = np.arange(0, 1001, 20)\n",
    "errors = []\n",
    "\n",
    "for num_iter in num_iters:\n",
    "    _, error = perceptron(X_training, Y_training, num_iter)\n",
    "    errors.append(error)\n",
    "\n",
    "plt.plot(num_iters, errors)\n",
    "plt.xlabel('Number of iterations')\n",
    "plt.ylabel('Training error')\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "# NOTE how the training loss decreases as we increase the number of iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Error of perceptron (3000 iterations): 28.328008519701807\n",
      "Test Error of perceptron (3000 iterations): 0.3\n"
     ]
    }
   ],
   "source": [
    "w_found, error = perceptron(X_training,Y_training, 3000)  \n",
    "print(\"Training Error of perceptron (3000 iterations): \" + str(error))\n",
    "\n",
    "num_errors, _ = count_errors(w_found, X_test,Y_test) \n",
    "\n",
    "true_loss_estimate = (num_errors / len(X_test))  \n",
    "print(\"Test Error of perceptron (3000 iterations): \" + str(true_loss_estimate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept: [-0.04674437]\n",
      "Coefficients: [[-0.04674437 -1.43821763  0.88923872  0.16852066]]\n",
      "Error rate on training set: 24.600638977635782\n",
      "Error rate on test set: 24.893617021276597\n"
     ]
    }
   ],
   "source": [
    "# part on logistic regression for 2 classes\n",
    "logreg = linear_model.LogisticRegression(C = 1e5) # C should be very large to ignore regularization (see above)\n",
    "\n",
    "# learn from training set: hint use fit(...)\n",
    "\n",
    "logreg.fit(X_training,Y_training)\n",
    "print(\"Intercept:\" , logreg.intercept_)\n",
    "print(\"Coefficients:\" , logreg.coef_)\n",
    "\n",
    "# predict on training set\n",
    "predicted_training = logreg.predict(X_training) \n",
    "\n",
    "# print the error rate = fraction of misclassified samples\n",
    "error_count_training = (predicted_training != Y_training).sum()\n",
    "error_rate_training = (error_count_training / len(X_training)) * 100 \n",
    "print(\"Error rate on training set: \"+str(error_rate_training))\n",
    "\n",
    "# predict on test set\n",
    "predicted_test = logreg.predict(X_test)\n",
    "\n",
    "#print the error rate = fraction of misclassified samples\n",
    "error_count_test = (predicted_test != Y_test).sum()\n",
    "error_rate_test =(error_count_test / len(X_test)) * 100 \n",
    "print(\"Error rate on test set: \" + str(error_rate_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names  = [\"Tenure in Months\",\"Monthly Charge\",\"Age\"]\n",
    "\n",
    "# Select the two features to use\n",
    "idx0 = 0 \n",
    "idx1 = 1 \n",
    "\n",
    "X_reduced = X[:,[idx0, idx1]]\n",
    "\n",
    "# re-initialize the dataset splits, with the reduced sets\n",
    "X_training = X_reduced[:m_training,:] \n",
    "Y_training = Y[:m_training, ] \n",
    "\n",
    "X_test = X_reduced[m_training:, :] \n",
    "Y_test = Y[m_training:,] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now learn a model using the training data and measure the performances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error rate on test set: 25.21276595744681\n"
     ]
    }
   ],
   "source": [
    "# learning from training data\n",
    "# predict on test set\n",
    "logreg.fit(X_training,Y_training)\n",
    "predicted_test = logreg.predict(X_test) \n",
    "\n",
    "#print the error rate = fraction of misclassified samples\n",
    "error_count_test = (predicted_test != Y_test).sum()\n",
    "\n",
    "# print the error rate = fraction of misclassified samples\n",
    "error_rate_test = (error_count_test / len(X_test)) * 100 \n",
    "print(\"Error rate on test set: \" + str(error_rate_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
